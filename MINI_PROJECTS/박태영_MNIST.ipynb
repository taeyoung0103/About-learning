{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c8fba3c",
   "metadata": {},
   "source": [
    "# MNIST Dataset 최적화\n",
    "    - val_accuracy: 0.99\n",
    "    - epochs 수\n",
    "    - 모델 크기\n",
    "    - dropout\n",
    "    - batchnormalization\n",
    "    \n",
    "월요일 9시 전까지 제출: kgmyh@naver.com\n",
    "노트북파일명 : 이름_mnist.ipynb\n",
    "제목 : 이름 딥러닝 과제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58166ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21c3eda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_image, train_label), (test_image, test_label) = keras.datasets.mnist.load_data()\n",
    "train_image.shape, test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "871ce952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터, 변수 정의\n",
    "\n",
    "LEARNING_RATE = 0.001   # 학습률 지정\n",
    "N_EPOCHS = 40   # epoch수  데이터를 몇번쓸지(몇번 반복할지를 정하는 수)\n",
    "N_BATCHS = 100    # 배치 사이즈\n",
    "\n",
    "# 변수\n",
    "N_TRAIN = train_X.shape[0]   # train 데이터셋의 데이터개수\n",
    "N_TEST = test_X.shape[0]     # test 데이터셋의 데이터개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dcad4700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y 전처리, \n",
    "\n",
    "X_train = (train_image/255.0).astype(np.float32)\n",
    "X_test = (test_image/255.0).astype(np.float32)\n",
    "\n",
    "y_train = keras.utils.to_categorical(train_label)\n",
    "y_test = keras.utils.to_categorical(test_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6d50e049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 생성\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(N_TRAIN).batch(N_BATCHS)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(N_BATCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4db5ba5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bn_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Flatten(input_shape=(28,28)))\n",
    "    \n",
    "    model.add(layers.Dense(units=1024)) #WX + b\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ReLU())#activation 함수\n",
    "    \n",
    "    \n",
    "    model.add(layers.Dense(units=1024))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ReLU())\n",
    "    \n",
    "    model.add(layers.Dense(units=512))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ReLU())\n",
    "    \n",
    "    model.add(layers.Dense(units=512))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ReLU())\n",
    "    \n",
    "    model.add(layers.Dense(units=256))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ReLU())\n",
    "    \n",
    "    model.add(layers.Dense(units=256))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ReLU())\n",
    "    \n",
    "    model.add(layers.Dense(units=10)) #출력\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Softmax())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2efa0fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1024)              803840    \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "re_lu_26 (ReLU)              (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "re_lu_27 (ReLU)              (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "re_lu_28 (ReLU)              (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "re_lu_29 (ReLU)              (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "re_lu_30 (ReLU)              (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "re_lu_31 (ReLU)              (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "softmax_5 (Softmax)          (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,854,962\n",
      "Trainable params: 2,847,774\n",
      "Non-trainable params: 7,188\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_bn_model()\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c600a678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer에 고정된 learning rate 대신에 Learning Rate Scheduler를 생성해서 등록\n",
    "lr_scheduler = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=LEARNING_RATE, # 초기(시작) 학습률\n",
    "                                                           decay_steps= 600*5, # 몇 step마다 learing rate를 변경할 것인지 지정. (1에폭당 600스텝-600*5: 5에폭 당 LR를 변경)\n",
    "                                                           decay_rate=0.5, # 변화율. 현재 Learning Rate * decay_rate = 새 Learing rate\n",
    "                                                           staircase=True # 계단형태로 떨어트릴지(True), step마다 조금씩 떨어트릴지(False) 설정\n",
    "                                                          )\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr_scheduler), \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "85407b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "600/600 [==============================] - 25s 39ms/step - loss: 0.3434 - accuracy: 0.9428 - val_loss: 0.1557 - val_accuracy: 0.9679\n",
      "Epoch 2/40\n",
      "600/600 [==============================] - 27s 44ms/step - loss: 0.1669 - accuracy: 0.9684 - val_loss: 0.1213 - val_accuracy: 0.9738\n",
      "Epoch 3/40\n",
      "600/600 [==============================] - 30s 50ms/step - loss: 0.1158 - accuracy: 0.9751 - val_loss: 0.0982 - val_accuracy: 0.9758\n",
      "Epoch 4/40\n",
      "600/600 [==============================] - 39s 65ms/step - loss: 0.0875 - accuracy: 0.9807 - val_loss: 0.1007 - val_accuracy: 0.9731\n",
      "Epoch 5/40\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0692 - accuracy: 0.9840 - val_loss: 0.0855 - val_accuracy: 0.9773\n",
      "Epoch 6/40\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0398 - accuracy: 0.9915 - val_loss: 0.0607 - val_accuracy: 0.9837\n",
      "Epoch 7/40\n",
      "600/600 [==============================] - 34s 56ms/step - loss: 0.0311 - accuracy: 0.9938 - val_loss: 0.0680 - val_accuracy: 0.9821\n",
      "Epoch 8/40\n",
      "600/600 [==============================] - 38s 63ms/step - loss: 0.0322 - accuracy: 0.9925 - val_loss: 0.0721 - val_accuracy: 0.9805\n",
      "Epoch 9/40\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0268 - accuracy: 0.9940 - val_loss: 0.0627 - val_accuracy: 0.9836\n",
      "Epoch 10/40\n",
      "600/600 [==============================] - 27s 44ms/step - loss: 0.0225 - accuracy: 0.9949 - val_loss: 0.0603 - val_accuracy: 0.9836\n",
      "Epoch 11/40\n",
      "600/600 [==============================] - 41s 68ms/step - loss: 0.0139 - accuracy: 0.9973 - val_loss: 0.0539 - val_accuracy: 0.9857\n",
      "Epoch 12/40\n",
      "600/600 [==============================] - 33s 54ms/step - loss: 0.0111 - accuracy: 0.9979 - val_loss: 0.0526 - val_accuracy: 0.9858\n",
      "Epoch 13/40\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0096 - accuracy: 0.9983 - val_loss: 0.0562 - val_accuracy: 0.9853\n",
      "Epoch 14/40\n",
      "600/600 [==============================] - 32s 54ms/step - loss: 0.0096 - accuracy: 0.9982 - val_loss: 0.0556 - val_accuracy: 0.9858\n",
      "Epoch 15/40\n",
      "600/600 [==============================] - 37s 61ms/step - loss: 0.0091 - accuracy: 0.9981 - val_loss: 0.0581 - val_accuracy: 0.9853\n",
      "Epoch 16/40\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0053 - accuracy: 0.9993 - val_loss: 0.0505 - val_accuracy: 0.9872\n",
      "Epoch 17/40\n",
      "600/600 [==============================] - 30s 50ms/step - loss: 0.0046 - accuracy: 0.9995 - val_loss: 0.0524 - val_accuracy: 0.9878\n",
      "Epoch 18/40\n",
      "600/600 [==============================] - 41s 69ms/step - loss: 0.0044 - accuracy: 0.9995 - val_loss: 0.0499 - val_accuracy: 0.9880\n",
      "Epoch 19/40\n",
      "600/600 [==============================] - 32s 54ms/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 0.0516 - val_accuracy: 0.9879\n",
      "Epoch 20/40\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 0.0511 - val_accuracy: 0.9878\n",
      "Epoch 21/40\n",
      "600/600 [==============================] - 35s 58ms/step - loss: 0.0029 - accuracy: 0.9997 - val_loss: 0.0507 - val_accuracy: 0.9883\n",
      "Epoch 22/40\n",
      "600/600 [==============================] - 41s 68ms/step - loss: 0.0033 - accuracy: 0.9997 - val_loss: 0.0542 - val_accuracy: 0.9878\n",
      "Epoch 23/40\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0026 - accuracy: 0.9998 - val_loss: 0.0520 - val_accuracy: 0.9875\n",
      "Epoch 24/40\n",
      "600/600 [==============================] - 31s 52ms/step - loss: 0.0023 - accuracy: 0.9998 - val_loss: 0.0545 - val_accuracy: 0.9877\n",
      "Epoch 25/40\n",
      "600/600 [==============================] - 42s 70ms/step - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.0547 - val_accuracy: 0.9876\n",
      "Epoch 26/40\n",
      "600/600 [==============================] - 31s 51ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.0537 - val_accuracy: 0.9880\n",
      "Epoch 27/40\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.0542 - val_accuracy: 0.9872\n",
      "Epoch 28/40\n",
      "600/600 [==============================] - 33s 54ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0541 - val_accuracy: 0.9874\n",
      "Epoch 29/40\n",
      "600/600 [==============================] - 44s 74ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0546 - val_accuracy: 0.9877\n",
      "Epoch 30/40\n",
      "600/600 [==============================] - 30s 49ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.0553 - val_accuracy: 0.9880\n",
      "Epoch 31/40\n",
      "600/600 [==============================] - 27s 46ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.0546 - val_accuracy: 0.9878\n",
      "Epoch 32/40\n",
      "600/600 [==============================] - 34s 56ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.0536 - val_accuracy: 0.9876\n",
      "Epoch 33/40\n",
      "600/600 [==============================] - 44s 74ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0542 - val_accuracy: 0.9870\n",
      "Epoch 34/40\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.0534 - val_accuracy: 0.9878\n",
      "Epoch 35/40\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0534 - val_accuracy: 0.9875\n",
      "Epoch 36/40\n",
      "600/600 [==============================] - 39s 65ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0534 - val_accuracy: 0.9878\n",
      "Epoch 37/40\n",
      "600/600 [==============================] - 43s 72ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0540 - val_accuracy: 0.9876\n",
      "Epoch 38/40\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0538 - val_accuracy: 0.9879\n",
      "Epoch 39/40\n",
      "600/600 [==============================] - 32s 53ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0534 - val_accuracy: 0.9879\n",
      "Epoch 40/40\n",
      "600/600 [==============================] - 44s 73ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0536 - val_accuracy: 0.9882\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train_dataset, epochs=N_EPOCHS, validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36698260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082766e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2069e4b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fbabee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84019ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dd6109",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
